{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73215349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "env_root = '/N/project/baby_vision_curriculum/pythonenvs/hfenv/lib/python3.10/site-packages/'\n",
    "sys.path.insert(0, env_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc16fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import torch, torchvision\n",
    "# from torchvision import transforms as tr\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "# import math\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6693a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "import json \n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19abcc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger __main__ (WARNING)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08dcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_retrieval(feature_dir, cfg):\n",
    "    \"\"\"Extract features from test split and search on train split features.\"\"\"\n",
    "    logger.info('Loading local .npy files...')\n",
    "    fold = cfg.get_int('dataset.fold')\n",
    "\n",
    "    X_train = np.load(os.path.join(feature_dir, f'train_fold{fold}_feats.npy'))\n",
    "    y_train = np.load(os.path.join(feature_dir, f'train_fold{fold}_labels.npy'))\n",
    "\n",
    "    X_test = np.load(os.path.join(feature_dir, f'test_fold{fold}_feats.npy'))\n",
    "    y_test = np.load(os.path.join(feature_dir, f'test_fold{fold}_labels.npy'))\n",
    "\n",
    "    ks = [1, 5, 10, 20, 50]\n",
    "    topk_correct = {k:0 for k in ks}\n",
    "\n",
    "    distances = cosine_distances(X_test, X_train)\n",
    "    indices = np.argsort(distances)\n",
    "\n",
    "    for k in ks:\n",
    "        # print(k)\n",
    "        top_k_indices = indices[:, :k]\n",
    "        # print(top_k_indices.shape, y_test.shape)\n",
    "        for ind, test_label in zip(top_k_indices, y_test):\n",
    "            labels = y_train[ind]\n",
    "            if test_label in labels:\n",
    "                # print(test_label, labels)\n",
    "                topk_correct[k] += 1\n",
    "\n",
    "    for k in ks:\n",
    "        correct = topk_correct[k]\n",
    "        total = len(X_test)\n",
    "        logger.info('Top-{}, correct = {:.2f}, total = {}, acc = {:.3f}'.format(k, correct, total, correct/total))\n",
    "\n",
    "    with open(os.path.join(feature_dir, f'topk_correct_fold{fold}.json'), 'w') as fp:\n",
    "        json.dump(topk_correct, fp)\n",
    "        \n",
    "def get_separability_score_old(df, label, method='sgd', ret_preds=False):\n",
    "    # method: sgd or svm\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(df[label])\n",
    "    \n",
    "    X_cols = ['dim'+str(i)\n",
    "              for i in range(768)]\n",
    "    X = df[X_cols]\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    if method=='svm':\n",
    "        clf = make_pipeline(StandardScaler(),\n",
    "                            LinearSVC(random_state=0, tol=1e-4))\n",
    "    elif method=='sgd':\n",
    "        clf = make_pipeline(StandardScaler(),\n",
    "                            SGDClassifier(max_iter=5000, tol=1e-4, n_jobs=20))#, loss='log_loss'))\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train,y_train)\n",
    "    test_score = clf.score(X_test,y_test)\n",
    "    if ret_preds:\n",
    "        preds = clf.predict(X_test)\n",
    "        return train_score, test_score, preds, y_test\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc6672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_score(df_train, df_test, label, metric='cosine',\n",
    "                 savedir=None, run_id=None):\n",
    "#     Get nearest neighbor score\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_train = le.fit_transform(df_train[label])\n",
    "    \n",
    "    X_cols = [col for col in df_train.columns if 'dim' in col]\n",
    "    x_train = df_train[X_cols]\n",
    "    \n",
    "    if df_test is not None:\n",
    "        x_test = df_test[X_cols]\n",
    "        y_test = le.transform(df_test[label])\n",
    "    \n",
    "    ks = [1, 5, 10, 20, 50]\n",
    "    topk_correct = {k:0 for k in ks}\n",
    "\n",
    "    if metric=='cosine':\n",
    "        distances = cosine_distances(x_test, x_train)\n",
    "    else:\n",
    "        distances = euclidean_distances(x_test, x_train)\n",
    "    indices = np.argsort(distances)\n",
    "    \n",
    "    for k in ks:\n",
    "        # print(k)\n",
    "        top_k_indices = indices[:, :k]\n",
    "        # print(top_k_indices.shape, y_test.shape)\n",
    "        for ind, test_label in zip(top_k_indices, y_test):\n",
    "            labels = y_train[ind]\n",
    "            if test_label in labels:\n",
    "                # print(test_label, labels)\n",
    "                topk_correct[k] += 1\n",
    "        topk_correct[k] = topk_correct[k]/len(y_test)\n",
    "    \n",
    "    for k in ks:\n",
    "        correct = topk_correct[k]\n",
    "        total = len(x_test)\n",
    "        logger.info('Top-{}, correct = {:.2f}, total = {}, acc = {:.3f}'.format(k, correct, total, correct/total))\n",
    "        print('Top-{}, correct = {:.2f}, total = {}, acc = {:.3f}'.format(k, correct, total, correct/total))\n",
    "\n",
    "    if savedir is not None:\n",
    "        if run_id is None:\n",
    "            raise ValueError\n",
    "            # run_id = ''\n",
    "        with open(os.path.join(savedir, \n",
    "                               run_id+'_topk_correct.json'), 'w') as fp:\n",
    "            json.dump(topk_correct, fp)\n",
    "\n",
    "    return topk_correct#[1], topk_correct[5], topk_correct[10]\n",
    "\n",
    "def get_separability_score(df_train, df_test, label, \n",
    "                           method='sgd', ret_preds=False,\n",
    "                          n_jobs=80):\n",
    "    # method: sgd or svm\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_train = le.fit_transform(df_train[label])\n",
    "    \n",
    "    X_cols = [col for col in df_train.columns if 'dim' in col]\n",
    "    x_train = df_train[X_cols]\n",
    "    \n",
    "    if df_test is not None:\n",
    "        x_test = df_test[X_cols]\n",
    "        y_test = le.transform(df_test[label])\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_train, y_train, test_size=0.33, random_state=42)\n",
    "    \n",
    "    if method=='svm':\n",
    "        clf = make_pipeline(StandardScaler(),\n",
    "                            LinearSVC(random_state=0, tol=1e-4))\n",
    "    elif method=='sgd':\n",
    "        clf = make_pipeline(StandardScaler(),\n",
    "                            SGDClassifier(max_iter=5000, tol=1e-4, n_jobs=n_jobs))#, loss='log_loss'))\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_score = clf.score(x_train,y_train)\n",
    "    test_score = clf.score(x_test,y_test)\n",
    "    if ret_preds:\n",
    "        preds = clf.predict(x_test)\n",
    "        return train_score, test_score, preds, y_test\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0dd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSv2Eval():\n",
    "    \n",
    "    def __init__(self, label_paths=None):\n",
    "        if label_paths is None:\n",
    "            label_paths={'train':'/N/project/baby_vision_curriculum/benchmarks/ssv2/easy_labels/train_easy10.csv',\n",
    "                         'test':'/N/project/baby_vision_curriculum/benchmarks/ssv2/easy_labels/val_easy10.csv'}        \n",
    "        self.labels_df = {x: pd.read_csv(label_paths[x])\n",
    "                         for x in ['train','test']}\n",
    "        for phase in ['train', 'test']:\n",
    "            self.labels_df[phase].set_index('fname', inplace=True)\n",
    "\n",
    "    def get_categorylabel(self, fname, phase):\n",
    "        return self.labels_df[phase].loc[str(fname)+'.webm', 'label']\n",
    "\n",
    "    def add_labels_to_df(self, df, labels, phase):\n",
    "        if 'category' in labels:\n",
    "            df['category'] = df['fnames'].apply(\n",
    "                lambda fname: self.get_categorylabel(fname, phase))\n",
    "        return df\n",
    "    \n",
    "    def proc_train_test(self, data_fpaths, score_type, eval_type='linear', n_jobs=80):\n",
    "        if score_type!='category':\n",
    "            raise ValueError\n",
    "        method='sgd'\n",
    "#         data_fpaths = {'train':fp_train, }\n",
    "        data_df = {}\n",
    "        for phase in ['train', 'test']:\n",
    "            data_df[phase] = pd.read_csv(\n",
    "                data_fpaths[phase])\n",
    "            data_df[phase] = self.add_labels_to_df(data_df[phase], ['category'], phase)\n",
    "        \n",
    "        if eval_type=='linear':\n",
    "            train_score, test_score, preds, targets = get_separability_score(\n",
    "                data_df['train'], data_df['test'], score_type, method=method, \n",
    "                ret_preds=True, n_jobs=n_jobs)\n",
    "        else:\n",
    "            test_score = get_nn_score(\n",
    "                data_df['train'], data_df['test'], score_type, metric='cosine',\n",
    "                 savedir=None, run_id=None)\n",
    "        \n",
    "        return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69a1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCF101Eval():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def add_labels_to_df(self, df):\n",
    "        df['category'] = df['fnames']#.apply(lambda fname: self.get_categorylabel(fname))\n",
    "        return df\n",
    "    \n",
    "    def proc_train_test(self, data_fpaths, score_type, eval_type='linear', n_jobs=80):\n",
    "        if score_type!='category':\n",
    "            raise ValueError\n",
    "        method='sgd'\n",
    "#         data_fpaths = {'train':fp_train, }\n",
    "        data_df = {}\n",
    "        for phase in ['train', 'test']:\n",
    "            data_df[phase] = pd.read_csv(\n",
    "                data_fpaths[phase])\n",
    "            data_df[phase] = self.add_labels_to_df(data_df[phase])\n",
    "        \n",
    "        if eval_type=='linear':\n",
    "            train_score, test_score, preds, targets = get_separability_score(\n",
    "                data_df['train'], data_df['test'], score_type, method=method, \n",
    "                ret_preds=True, n_jobs=n_jobs)\n",
    "        else:\n",
    "            test_score = get_nn_score(\n",
    "                data_df['train'], data_df['test'], score_type, metric='cosine',\n",
    "                 savedir=None, run_id=None)\n",
    "        \n",
    "        return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba45975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example name: airplane_01_pivothead_absent.mp4\n",
    "\n",
    "class ToyBoxEval():\n",
    "    \n",
    "    def __init__(self, exemplar=True):\n",
    "        self.exemplar = exemplar\n",
    "#         in the categorization test, the train and test are divided by exemplars.\n",
    "    \n",
    "    def get_exemplar_split(self, df, test_size=0.33, random_state=42):\n",
    "        \n",
    "        categories_unq = df['category'].unique()\n",
    "        \n",
    "        train_rows, test_rows = [],[]\n",
    "        for i_c, cat in enumerate(categories_unq):\n",
    "            cdata = df[df['category']==cat]\n",
    "            identities_unq = cdata['identity'].unique()\n",
    "            identity_train, identity_test = train_test_split(identities_unq, test_size=test_size)\n",
    "#             print('identity_train:',identity_train[:10],\n",
    "#                   'identity_test:',identity_test[:10]) #@@@\n",
    "#                                               random_state=random_state)\n",
    "            train_rows.append(\n",
    "                cdata[cdata['identity'].isin(identity_train)])\n",
    "            test_rows.append(\n",
    "                cdata[cdata['identity'].isin(identity_test)])\n",
    "        train_df = pd.concat(train_rows, axis=0, ignore_index=True)\n",
    "        test_df = pd.concat(test_rows, axis=0, ignore_index=True)\n",
    "        \n",
    "#         print('finished get_exemplar_split') #@@@\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    \n",
    "    def get_separability_score(self, df, label, method='sgd', ret_preds=False):\n",
    "#         use self.get_exemplar_split\n",
    "\n",
    "        train_df, test_df = self.get_exemplar_split(df, test_size=0.33)#, random_state=42)\n",
    "\n",
    "        le = preprocessing.LabelEncoder().fit(df[label])\n",
    "        X_cols = sorted([col for col in df.columns if 'dim' in col])\n",
    "        \n",
    "        y_train = le.transform(train_df[label])\n",
    "        y_test = le.transform(test_df[label])\n",
    "        \n",
    "        X_train, X_test = train_df[X_cols], test_df[X_cols]\n",
    "\n",
    "#         print('train_df[label]',train_df[label].iloc[::100])\n",
    "#         print('x_train.shape', X_train.shape)\n",
    "        \n",
    "        if method=='svm':\n",
    "            clf = make_pipeline(StandardScaler(),\n",
    "                                LinearSVC(random_state=0, tol=1e-4))\n",
    "        elif method=='sgd':\n",
    "            clf = make_pipeline(StandardScaler(),\n",
    "                                SGDClassifier(max_iter=5000, tol=1e-4, n_jobs=20))#, loss='log_loss'))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_score = clf.score(X_train,y_train)\n",
    "        test_score = clf.score(X_test,y_test)\n",
    "        if ret_preds:\n",
    "            preds = clf.predict(X_test)\n",
    "            return train_score, test_score, preds, y_test\n",
    "        return train_score, test_score\n",
    "\n",
    "        \n",
    "    def get_labels(self, fname):\n",
    "    #     example fname: truck_30_pivothead_rzminus.mp4\n",
    "        fnparts = fname.split('.')[0].split('_')\n",
    "        category = fnparts[0]\n",
    "        identity = category+fnparts[1]\n",
    "        trans = fnparts[3]\n",
    "        return category, identity, trans\n",
    "\n",
    "    def get_categorylabel(self, fname):\n",
    "        fnparts = fname.split('.')[0].split('_')\n",
    "        category = fnparts[0]\n",
    "        return category\n",
    "\n",
    "    def get_identitylabel(self, fname):\n",
    "        fnparts = fname.split('.')[0].split('_')\n",
    "        category = fnparts[0]\n",
    "        identity = category+fnparts[1]\n",
    "        return identity\n",
    "\n",
    "    def get_translabel(self, fname):\n",
    "        fnparts = fname.split('.')[0].split('_')\n",
    "        translabel = fnparts[3]\n",
    "        return translabel\n",
    "\n",
    "    def add_labels_to_df(self, df, labels):\n",
    "        if 'category' in labels:\n",
    "            df['category'] = df['fnames'].apply(lambda fname: self.get_categorylabel(fname))\n",
    "        if 'identity' in labels:\n",
    "            df['identity'] = df['fnames'].apply(lambda fname: self.get_identitylabel(fname))\n",
    "        if 'transformation' in labels:\n",
    "            df['transformation'] = df['fnames'].apply(lambda fname: self.get_translabel(fname))\n",
    "        return df\n",
    "    \n",
    "    def fix_fnames(self, df):\n",
    "        df.iloc[2163,0] = 'giraffe_02_pivothead_rzplus.mp4'\n",
    "        df.iloc[1851,0]='duck_06_pivothead_rxminus.mp4'\n",
    "        df.iloc[751,0] = 'car_03_pivothead_rzminus.mp4'\n",
    "        return df\n",
    "    \n",
    "    def proc_fp(self, fp, score_type):\n",
    "        df = pd.read_csv(fp)\n",
    "        df = self.fix_fnames(df)\n",
    "        \n",
    "        df = self.add_labels_to_df(df, ['category', 'identity','transformation'])\n",
    "        method='sgd'\n",
    "        \n",
    "        if (score_type=='category') and self.exemplar:\n",
    "            train_score, test_score, preds, targets = self.get_separability_score(\n",
    "                df, score_type, method=method, ret_preds=True)\n",
    "        else:\n",
    "#             use the generic method of get_separability_score\n",
    "            train_score, test_score, preds, targets = get_separability_score(\n",
    "                df, None, score_type, method=method, ret_preds=True)\n",
    "        return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23cb44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traingroups(curr, stage):\n",
    "    if curr=='dev':\n",
    "        return 'g0g1g2'[:2*stage]\n",
    "    elif curr=='adev':\n",
    "        return 'g2g1g0'[:2*stage]\n",
    "    else:\n",
    "        return 'na'\n",
    "    \n",
    "def parse_fname(fp):\n",
    "# embeddings_adev_1_g2_default_0_246.csv'\n",
    "    parts = Path(fp).stem.split('_')\n",
    "    if len(parts)<7:\n",
    "        print('Filename does not match the format')\n",
    "        if 'na' in parts:\n",
    "            prefix, curr, stage, current_gr, cond, fold, seed = \\\n",
    "                'embeddings', 'untrained', '0', 'na', 'na', '0', '0' \n",
    "#             train_gr = 'na'\n",
    "    \n",
    "    else:\n",
    "        prefix, curr, stage, current_gr, cond, fold, seed = parts\n",
    "    stage=int(stage)\n",
    "    train_gr = get_traingroups(curr, stage)\n",
    "    \n",
    "    tag_dict = {\n",
    "        'Curriculum':curr,\n",
    "        'Stage': stage,\n",
    "        'Condition':cond,\n",
    "        'Seed': seed,\n",
    "        'Train Groups': train_gr,\n",
    "        'data_id': '_'.join([curr, seed, cond])\n",
    "    }\n",
    "    return tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e38ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_result_folder_tb(emb_root, ds_task, iter_per_stage, eval_type, \n",
    "                       n_jobs=80, exemplar=False):\n",
    "    if ds_task=='tb_cat':\n",
    "        evaluator = ToyBoxEval(exemplar=exemplar)\n",
    "        ds_task = 'category'\n",
    "    elif ds_task=='tb_trans':\n",
    "        evaluator = ToyBoxEval(exemplar=exemplar)\n",
    "        ds_task = 'transformation'\n",
    "    else:\n",
    "        raise ValueError('only for toybox')\n",
    "    record_list = []\n",
    "    \n",
    "\n",
    "    fpathlist = [emb_root+fname\n",
    "                for fname in os.listdir(emb_root)\n",
    "                if Path(emb_root+fname).suffix=='.csv']\n",
    "        \n",
    "    if n_jobs>1:\n",
    "        record_list = Parallel(n_jobs=n_jobs_external)(\n",
    "            delayed(job_proc_file)(fp, ds_task, evaluator, iter_per_stage)\n",
    "            for fp in tqdm(fpathlist)\n",
    "        )\n",
    "    else:\n",
    "        for fp in tqdm(fpathlist):\n",
    "#             print(fp)\n",
    "            record = parse_fname(fp)\n",
    "    #         if '141' in fp:\n",
    "    #             continue\n",
    "            record[ds_task] = evaluator.proc_fp(fp, ds_task)\n",
    "            record['Iteration']=iter_per_stage*record['Stage']\n",
    "            record_list.append(deepcopy(record))\n",
    "            \n",
    "#             break #@@@\n",
    "    df = pd.DataFrame.from_records(record_list)         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c55d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_result_folder(emb_root, ds_task, iter_per_stage, eval_type, \n",
    "                       n_jobs=80):\n",
    "    if ds_task=='ssv2':\n",
    "        evaluator = SSv2Eval()\n",
    "        ds_task = 'category'\n",
    "    elif ds_task=='tb_cat':\n",
    "        evaluator = ToyBoxEval()\n",
    "        ds_task = 'category'\n",
    "    elif ds_task=='tb_trans':\n",
    "        evaluator = ToyBoxEval()\n",
    "        ds_task = 'transformation'\n",
    "    elif ds_task=='cifar10':\n",
    "        evaluator = Cifar10Eval()\n",
    "        ds_task = 'category'\n",
    "    elif ds_task=='ucf101':\n",
    "        evaluator = UCF101Eval()\n",
    "        ds_task = 'category'\n",
    "        n_jobs_external=n_jobs\n",
    "        n_jobs_internal=1\n",
    "    else:\n",
    "        raise ValueError\n",
    "    record_list = []\n",
    "    \n",
    "    if (ds_task=='tb_cat') |(ds_task=='tb_trans'):\n",
    "        fpathlist = [emb_root+fname\n",
    "                    for fname in os.listdir(emb_root)\n",
    "                    if Path(emb_root+fname).suffix=='.csv']\n",
    "        \n",
    "    \n",
    "    train_test_fp_list = []\n",
    "    for fname in os.listdir(emb_root):\n",
    "        if Path(emb_root+fname).suffix!='.csv':\n",
    "            continue\n",
    "        train_fp = emb_root+fname\n",
    "        test_fp = str(Path(emb_root, 'test/', fname))\n",
    "        \n",
    "        if not os.path.exists(test_fp):\n",
    "            print(test_fp, 'does not exist')\n",
    "            continue\n",
    "        train_test_fp_list.append(\n",
    "            {'train':train_fp,\n",
    "             'test':test_fp})\n",
    "    \n",
    "\n",
    "    for fp_dict in tqdm(train_test_fp_list):\n",
    "#             print(fp)\n",
    "        record = parse_fname(fp_dict['train'])\n",
    "        if eval_type=='linear':\n",
    "            record[ds_task] = evaluator.proc_train_test(fp_dict, ds_task,\n",
    "                                                       eval_type=eval_type, \n",
    "                                                        n_jobs=n_jobs)\n",
    "        else:\n",
    "            topkcorrect = evaluator.proc_train_test(fp_dict, ds_task,\n",
    "                                                       eval_type=eval_type, \n",
    "                                                        n_jobs=n_jobs)\n",
    "            record['Top1'] = topkcorrect[1]\n",
    "            record['Top5'] = topkcorrect[5]\n",
    "            record['Top10'] = topkcorrect[10]\n",
    "        record['Iteration']=iter_per_stage*record['Stage']\n",
    "        record_list.append(deepcopy(record))\n",
    "        \n",
    "    df = pd.DataFrame.from_records(record_list)         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ac733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                          | 1/37 [00:01<01:09,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.18, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.53, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.72, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▍                                         | 2/37 [00:03<01:06,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.10, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.42, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.85, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▌                                        | 3/37 [00:05<01:04,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.23, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.58, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.75, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▊                                       | 4/37 [00:07<01:02,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.14, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.47, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.68, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▉                                      | 5/37 [00:09<01:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.16, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.49, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.69, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|███████▏                                    | 6/37 [00:11<00:58,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.11, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.42, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.65, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|████████▎                                   | 7/37 [00:13<01:01,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.18, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.52, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.71, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████▌                                  | 8/37 [00:15<00:57,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.11, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.39, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n",
      "Filename does not match the format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████▋                                 | 9/37 [00:17<00:53,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.10, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.42, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████▌                               | 10/37 [00:19<00:56,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.20, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.56, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.76, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████▊                              | 11/37 [00:21<00:52,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.21, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.59, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.75, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████▉                             | 12/37 [00:23<00:49,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.20, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.57, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.75, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████                            | 13/37 [00:25<00:46,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.11, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.85, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████▎                          | 14/37 [00:27<00:44,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.20, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.59, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.77, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.90, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████▍                         | 15/37 [00:29<00:41,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.22, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.60, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.76, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.90, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████▌                        | 16/37 [00:30<00:39,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.12, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.65, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.84, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|███████████████████▊                       | 17/37 [00:32<00:37,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.10, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.84, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████▉                      | 18/37 [00:34<00:36,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.10, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.42, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.84, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████                     | 19/37 [00:36<00:34,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.17, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.50, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.70, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████▏                   | 20/37 [00:38<00:31,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.13, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.67, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.85, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████▍                  | 21/37 [00:40<00:29,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.20, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.57, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.76, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████████████████████████▌                 | 22/37 [00:42<00:27,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.17, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.52, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.71, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████▋                | 23/37 [00:43<00:25,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.10, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.65, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.85, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▉               | 24/37 [00:45<00:24,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.19, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.54, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.73, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████████              | 25/37 [00:47<00:21,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.09, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▏            | 26/37 [00:49<00:20,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.22, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.61, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.77, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████▍           | 27/37 [00:51<00:18,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.21, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.56, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.74, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████▌          | 28/37 [00:53<00:16,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.09, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.43, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.63, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.85, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|█████████████████████████████████▋         | 29/37 [00:55<00:14,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.18, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.52, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.70, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████▊        | 30/37 [00:56<00:13,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.23, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.60, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.79, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.90, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████       | 31/37 [00:58<00:11,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.12, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.42, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.64, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████▏     | 32/37 [01:00<00:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.11, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.41, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.66, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████▎    | 33/37 [01:02<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.16, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.48, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.69, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████▌   | 34/37 [01:04<00:05,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.11, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.44, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.65, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.86, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████▋  | 35/37 [01:06<00:03,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.14, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.46, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.67, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.88, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.99, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████▊ | 36/37 [01:08<00:01,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.24, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.58, total = 1000, acc = 0.001\n",
      "Top-10, correct = 0.76, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.89, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.97, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 37/37 [01:09<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1, correct = 0.14, total = 1000, acc = 0.000\n",
      "Top-5, correct = 0.49, total = 1000, acc = 0.000\n",
      "Top-10, correct = 0.69, total = 1000, acc = 0.001\n",
      "Top-20, correct = 0.87, total = 1000, acc = 0.001\n",
      "Top-50, correct = 0.98, total = 1000, acc = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learner = 'generative/'#'contrastive/'#'predictive/'#\n",
    "ds_task = 'ssv2'\n",
    "date = 'sep28'#'aug11'#'aug1'#'jul315'#\n",
    "num_ep,iter_per_ep = 5, 2000\n",
    "\n",
    "eval_type='nn'#'linear'#\n",
    "\n",
    "emb_root = '/N/project/baby_vision_curriculum/trained_models/'+learner+date+'/benchmarks/'+ds_task+'/'\n",
    "# emb_root = '/N/project/baby_vision_curriculum/trained_models/generative/v3/jul28dev/benchmarks/ssv2/'\n",
    "\n",
    "iter_per_stage = num_ep*iter_per_ep\n",
    "\n",
    "df_ss = proc_result_folder(emb_root, ds_task, iter_per_stage, eval_type, n_jobs=23)\n",
    "# df_ss.to_csv(date+'_'+ds_task+'_'+eval_type+'_score.csv', index=False)\n",
    "# df_ss.groupby(['Stage', 'Condition', 'Curriculum']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3427a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
